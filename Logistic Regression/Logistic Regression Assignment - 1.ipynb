{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dad6810",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between linear regression and logistic regression models. Provide an example of a scenario where logistic regression would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e67d96",
   "metadata": {},
   "source": [
    "Ans : \n",
    "1. Linear Regression is a model used in regression usecase where in we are trying to predict continuous values. \n",
    "2. On the other hand logistic regression is used for classification use case.\n",
    "3. A scenario where we want to predict whether a student will pass or fail an exam based on factors like study hours, attendance, previous grades, etc. Here, the outcome is binary (pass/fail), making logistic regression more suitable for this classification task. It estimates the probability of a student passing based on the given factors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b6702",
   "metadata": {},
   "source": [
    "Q2. What is the cost function used in logistic regression, and how is it optimized?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39681fc7",
   "metadata": {},
   "source": [
    "Ans :\n",
    "1. The cost function used in linear regression log loss error function.\n",
    "2. In the cost function the parameters that can be adjusted are x1 and x2 if we consider the two features in the data, by this we adjust the convergance algorithm and can optimized to find global minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986250fc",
   "metadata": {},
   "source": [
    "Q3. Explain the concept of regularization in logistic regression and how it helps prevent overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee05a2c",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "1. In scenarios where dataset is too small to train the models tends to overfit so as to capture all avaialable patterns we make use of regularization as the cost function returns the error zero every time.\n",
    "\n",
    "2. A penalty is added to generalize the model which is lambda * sum(slope^2). This adds a error to the final value and makes the model more generalize.\n",
    "\n",
    "3. By this the line of best fit and subsequent squashing is more more general in its trends"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea50fc",
   "metadata": {},
   "source": [
    "Q4. What is the ROC curve, and how is it used to evaluate the performance of the logistic regression\n",
    "model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9a15a1",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. The Receiver Operating Characteristic (ROC) curve is a graphical representation used to evaluate the performance of classification models, including logistic regression. It illustrates the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) across different threshold values.\n",
    "2. For a logistic regression model:\n",
    "    1. The model outputs probabilities between 0 and 1.\n",
    "    2. By adjusting the classification threshold (e.g., if the predicted probability is above a certain threshold, classify as positive), you can generate different points on the ROC curve.\n",
    "    3. The curve summarizes the model's performance across various threshold values without being influenced by the specific choice of threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e90ecb",
   "metadata": {},
   "source": [
    "Q5. What are some common techniques for feature selection in logistic regression? How do these\n",
    "techniques help improve the model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32904415",
   "metadata": {},
   "source": [
    "Ans:\n",
    "Following are the avaialable methods - \n",
    "1. Univariate Feature Selection: This method involves selecting features based on statistical tests like chi-square for categorical variables or ANOVA for numerical variables. It evaluates each feature individually in relation to the target variable and selects the most informative ones.\n",
    "2.Recursive Feature Elimination (RFE): RFE works by recursively fitting the model and eliminating the least significant features. It ranks features by their importance and removes the least significant ones until the specified number of features is reached or performance stops improving.\n",
    "3.Lasso Regression (L1 Regularization): Lasso regression adds a penalty term based on the absolute value of the coefficients to the cost function. This encourages sparse coefficients, effectively performing feature selection by driving less important feature coefficients to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e0771",
   "metadata": {},
   "source": [
    "Q6. How can you handle imbalanced datasets in logistic regression? What are some strategies for dealing\n",
    "with class imbalance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd31c1",
   "metadata": {},
   "source": [
    "Ans:\n",
    "Availaible methods are : \n",
    "1. Undersampling: Randomly remove samples from the majority class to balance the class distribution.\n",
    "2. Oversampling: Replicate samples from the minority class to balance the class distribution. Techniques like SMOTE (Synthetic Minority Over-sampling Technique) generate synthetic samples based on the existing minority class instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbbb6a3",
   "metadata": {},
   "source": [
    "Q7. Can you discuss some common issues and challenges that may arise when implementing logistic\n",
    "regression, and how they can be addressed? For example, what can be done if there is multicollinearity\n",
    "among the independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dd9c71",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. Multicollinearity among Independent Variables:\n",
    "\n",
    "    Issue: When independent variables are highly correlated, it can lead to unstable coefficient estimates and make it challenging to interpret the individual effects of predictors.\n",
    "    Solution:\n",
    "        1. Remove one of the correlated variables.\n",
    "        2. Perform dimensionality reduction techniques like PCA to create uncorrelated components.\n",
    "        3. Use regularization techniques like Lasso regression that automatically perform feature selection by driving less important coefficients to zero.\n",
    "\n",
    "2. Overfitting:\n",
    "\n",
    "    Issue: Logistic regression can overfit the training data, leading to poor generalization on unseen data.\n",
    "    Solution:\n",
    "        1. Regularization techniques like Ridge or Lasso regression help prevent overfitting by  penalizing large coefficients.\n",
    "        2. Cross-validation can be used to tune hyperparameters and prevent overfitting.\n",
    "\n",
    "3. Imbalanced Classes:\n",
    "\n",
    "    Issue: Imbalanced datasets can cause the model to bias towards the majority class and perform poorly on the minority class.\n",
    "    Solution: \n",
    "        1. Refer to the strategies mentioned earlier for handling imbalanced datasets, such as resampling techniques, adjusting class weights, or using appropriate evaluation metrics.\n",
    "\n",
    "4. Outliers:\n",
    "\n",
    "    Issue: Outliers can disproportionately influence the logistic regression coefficients and predictions.\n",
    "    Solution:\n",
    "        1. Detect and handle outliers by removing or transforming them if they are not representative of the underlying data distribution.\n",
    "        2. Use robust regression techniques that are less sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2280b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
